@inproceedings{lin_pagraph_2020,
 abstract = {Emerging graph neural networks (GNNs) have extended the successes of deep learning techniques against datasets like images and texts to more complex graph-structured data. By leveraging GPU accelerators, existing frameworks combine both mini-batch and sampling for effective and efficient model training on large graphs. However, this setup faces a scalability issue since loading rich vertices features from CPU to GPU through a limited bandwidth link usually dominates the training cycle. In this paper, we propose PaGraph, a system that supports general and efficient sampling-based GNN training on single-server with multi-GPU. PaGraph significantly reduces the data loading time by exploiting available GPU resources to keep frequently accessed graph data with a cache. It also embodies a lightweight yet effective caching policy that takes into account graph structural information and data access patterns of sampling-based GNN training simultaneously. Furthermore, to scale out on multiple GPUs, PaGraph develops a fast GNN-computation-aware partition algorithm to avoid cross-partition access during data parallel training and achieves better cache efficiency. Evaluations on two representative GNN models, GCN and GraphSAGE, show that PaGraph achieves up to 96.8% data loading time reductions and up to 4.8× performance speedup over the state-of-the-art baselines. Together with preprocessing optimization, PaGraph further delivers up to 16.0× end-to-end speedup.},
 address = {Virtual Event USA},
 author = {Lin, Zhiqi and Li, Cheng and Miao, Youshan and Liu, Yunxin and Xu, Yinlong},
 booktitle = {Proceedings of the 11th ACM Symposium on Cloud Computing},
 doi = {10.1145/3419111.3421281},
 file = {Lin 等。 - 2020 - PaGraph Scaling GNN training on large graphs via .pdf:files/16/Lin 等。 - 2020 - PaGraph Scaling GNN training on large graphs via .pdf:application/pdf},
 isbn = {978-1-4503-8137-6},
 language = {en},
 month = {October},
 pages = {401--415},
 publisher = {ACM},
 shorttitle = {PaGraph},
 title = {PaGraph: Scaling GNN training on large graphs via computation-aware caching},
 url = {https://dl.acm.org/doi/10.1145/3419111.3421281},
 urldate = {2020-12-26},
 year = {2020}
}

